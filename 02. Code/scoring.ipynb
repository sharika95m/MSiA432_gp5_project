{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use multiple GPUs or not\n",
    "\n",
    "use_multi_gpu = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-28 20:04:59.116076: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-28 20:05:00.293889: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-28 20:05:05.232685: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 36000 validated image filenames.\n",
      "Found 9000 validated image filenames.\n",
      "Found 5000 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "attr = pd.read_csv('list_attr_celeba.csv')\n",
    "features = ['image_id', 'Attractive', 'Bangs', 'Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Gray_Hair', 'Male', 'Oval_Face', 'Receding_Hairline', 'Smiling']\n",
    "\n",
    "attr_selected = attr.loc[:, features].iloc[:50000,:]\n",
    "attr_selected = attr_selected.replace(-1,0)\n",
    "\n",
    "train_df, test_df = train_test_split(attr_selected, test_size=0.1)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2)\n",
    "\n",
    "features = ['Attractive', 'Bangs', 'Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Gray_Hair', 'Male', 'Oval_Face', 'Receding_Hairline', 'Smiling']\n",
    "for feature in features:\n",
    "    train_df[feature] = train_df[feature].astype('float32')\n",
    "    val_df[feature] = val_df[feature].astype('float32')\n",
    "    test_df[feature] = test_df[feature].astype('float32')\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "img_height = 128\n",
    "img_width = 128\n",
    "\n",
    "# Create ImageDataGenerators\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, horizontal_flip=True, zoom_range=0.2, shear_range=0.2)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(train_df, directory=\"img_align_celeba/img_align_celeba\", \n",
    "                                                    x_col=\"image_id\", y_col=features,\n",
    "                                                    target_size=(img_height, img_width), \n",
    "                                                    batch_size=batch_size, class_mode='raw')\n",
    "\n",
    "val_generator = train_datagen.flow_from_dataframe(val_df, directory=\"img_align_celeba/img_align_celeba\", \n",
    "                                                    x_col=\"image_id\", y_col=features,\n",
    "                                                    target_size=(img_height, img_width), \n",
    "                                                    batch_size=batch_size, class_mode='raw')\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(test_df, directory=\"img_align_celeba/img_align_celeba\", \n",
    "                                                  x_col=\"image_id\", y_col=features, \n",
    "                                                  target_size=(img_height, img_width), \n",
    "                                                  batch_size=batch_size, class_mode='raw', shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-01 20:21:51.052491: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-06-01 20:21:51.128932: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-01 20:21:53.079088: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  5\n",
      "Using GPUs:  ['/physical_device:GPU:1', '/physical_device:GPU:2', '/physical_device:GPU:3', '/physical_device:GPU:4']\n",
      "WARNING:tensorflow:NCCL is not supported when using virtual GPUs, fallingback to reduction to one device\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3', '/job:localhost/replica:0/task:0/device:GPU:4')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-01 20:22:00.401612: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 35839 MB memory:  -> device: 1, name: NVIDIA RTX A6000, pci bus id: 0000:1b:00.0, compute capability: 8.6\n",
      "2023-06-01 20:22:00.402509: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 40959 MB memory:  -> device: 2, name: NVIDIA RTX A6000, pci bus id: 0000:88:00.0, compute capability: 8.6\n",
      "2023-06-01 20:22:00.403121: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 40959 MB memory:  -> device: 3, name: NVIDIA RTX A6000, pci bus id: 0000:89:00.0, compute capability: 8.6\n",
      "2023-06-01 20:22:00.403806: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 40959 MB memory:  -> device: 4, name: NVIDIA RTX A6000, pci bus id: 0000:b1:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# Distribute load over all GPU\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "if use_multi_gpu:\n",
    "    def set_gpus(*gpu_indices):\n",
    "        # Get list of GPUs\n",
    "        gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "        print(\"Num GPUs Available: \", len(gpus))\n",
    "\n",
    "        if gpus:\n",
    "            visible_gpus = [gpus[i] for i in gpu_indices]\n",
    "            try:\n",
    "                # Only use specified GPUs and ignore the others\n",
    "                tf.config.experimental.set_visible_devices(visible_gpus, 'GPU')\n",
    "                for gpu in visible_gpus:\n",
    "                    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "                print(\"Using GPUs: \", [gpu.name for gpu in visible_gpus])\n",
    "            except RuntimeError as e:\n",
    "                print(e)\n",
    "        return visible_gpus\n",
    "\n",
    "    # Call the function with the indices of the GPUs you want to use\n",
    "    visible_gpus = set_gpus(1, 2, 3, 4)  # Use the second, third, fourth, and fifth GPU\n",
    "\n",
    "    # Extract names of the GPUs being used\n",
    "    gpu_names = ['/device:GPU:' + gpu.name.split(':')[-1] for gpu in visible_gpus]\n",
    "\n",
    "    strategy = tf.distribute.MirroredStrategy(devices=gpu_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "if use_multi_gpu:\n",
    "    with strategy.scope():\n",
    "    # Load the pre-trained model from the h5 file\n",
    "        model = load_model('custom_model1.h5')\n",
    "\n",
    "        # Making predictions\n",
    "        y_pred = model.predict(test_generator)\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "        # The true labels can be accessed via the classes attribute of the generator\n",
    "        # y_true = test_generator.classes\n",
    "\n",
    "        # Since class_mode was set to 'raw' in the test_generator, classes contain the raw labels\n",
    "        y_true = np.concatenate([test_generator[i][1] for i in range(len(test_generator))], axis=0)\n",
    "        y_true = np.argmax(y_true, axis=1)\n",
    "\n",
    "        # Compute F1 score\n",
    "        f1 = f1_score(y_true, y_pred, average='macro')  # 'macro' for unweighted mean, 'weighted' for weighted mean\n",
    "        print('F1 Score:', f1)\n",
    "\n",
    "        loss, accuracy = model.evaluate(test_generator, steps=len(test_generator), verbose=0)\n",
    "        print(f'Test loss for the model : {loss:.4f}')\n",
    "        print(f'Test accuracy for the model: {accuracy:.4f}')\n",
    "\n",
    "else:\n",
    "    model = load_model('custom_model1.h5')\n",
    "\n",
    "    # Making predictions\n",
    "    y_pred = model.predict(test_generator)\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    # The true labels can be accessed via the classes attribute of the generator\n",
    "    # y_true = test_generator.classes\n",
    "\n",
    "    # Since class_mode was set to 'raw' in the test_generator, classes contain the raw labels\n",
    "    y_true = np.concatenate([test_generator[i][1] for i in range(len(test_generator))], axis=0)\n",
    "    y_true = np.argmax(y_true, axis=1)\n",
    "\n",
    "    # Compute F1 score\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')  # 'macro' for unweighted mean, 'weighted' for weighted mean\n",
    "    print('F1 Score:', f1)\n",
    "\n",
    "    loss, accuracy = model.evaluate(test_generator, steps=len(test_generator), verbose=0)\n",
    "    print(f'Test loss for the model : {loss:.4f}')\n",
    "    print(f'Test accuracy for the model: {accuracy:.4f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom model best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "if use_multi_gpu:\n",
    "    with strategy.scope():\n",
    "    # Load the pre-trained model from the h5 file\n",
    "        model = load_model('custom_model_4_blocks_best.h5')\n",
    "\n",
    "        # Making predictions\n",
    "        y_pred = model.predict(test_generator)\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "        # The true labels can be accessed via the classes attribute of the generator\n",
    "        # y_true = test_generator.classes\n",
    "\n",
    "        # Since class_mode was set to 'raw' in the test_generator, classes contain the raw labels\n",
    "        y_true = np.concatenate([test_generator[i][1] for i in range(len(test_generator))], axis=0)\n",
    "        y_true = np.argmax(y_true, axis=1)\n",
    "\n",
    "        # Compute F1 score\n",
    "        f1 = f1_score(y_true, y_pred, average='macro')  # 'macro' for unweighted mean, 'weighted' for weighted mean\n",
    "        print('F1 Score:', f1)\n",
    "        loss, accuracy = model.evaluate(test_generator, steps=len(test_generator), verbose=0)\n",
    "        print(f'Test loss for the model : {loss:.4f}')\n",
    "        print(f'Test accuracy for the model: {accuracy:.4f}')\n",
    "\n",
    "else:\n",
    "    model = load_model('custom_model_4_blocks_best.h5')\n",
    "\n",
    "    # Making predictions\n",
    "    y_pred = model.predict(test_generator)\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    # The true labels can be accessed via the classes attribute of the generator\n",
    "    # y_true = test_generator.classes\n",
    "\n",
    "    # Since class_mode was set to 'raw' in the test_generator, classes contain the raw labels\n",
    "    y_true = np.concatenate([test_generator[i][1] for i in range(len(test_generator))], axis=0)\n",
    "    y_true = np.argmax(y_true, axis=1)\n",
    "\n",
    "    # Compute F1 score\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')  # 'macro' for unweighted mean, 'weighted' for weighted mean\n",
    "    print('F1 Score:', f1)\n",
    "\n",
    "    loss, accuracy = model.evaluate(test_generator, steps=len(test_generator), verbose=0)\n",
    "    print(f'Test loss for the model : {loss:.4f}')\n",
    "    print(f'Test accuracy for the model: {accuracy:.4f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-28 20:08:54.683903: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-05-28 20:08:54.684100: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-05-28 20:08:54.684880: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:786] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorDataset/_1\"\n",
      "op: \"TensorDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 1\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\020TensorDataset:42\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT32\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "2023-05-28 20:08:54.698648: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-05-28 20:08:54.698857: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-05-28 20:08:54.879640: W tensorflow/core/framework/dataset.cc:807] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2023-05-28 20:08:54.879977: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype variant\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-05-28 20:08:54.899992: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-05-28 20:08:54.900219: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-05-28 20:08:55.073391: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype variant\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 17s 142ms/step\n",
      "F1 Score: 0.18993428852847458\n"
     ]
    }
   ],
   "source": [
    "if use_multi_gpu:\n",
    "    with strategy.scope():\n",
    "    # Load the pre-trained model from the h5 file\n",
    "        model = load_model('resnet50.h5')\n",
    "\n",
    "        # Making predictions\n",
    "        y_pred = model.predict(test_generator)\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "        # The true labels can be accessed via the classes attribute of the generator\n",
    "        # y_true = test_generator.classes\n",
    "\n",
    "        # Since class_mode was set to 'raw' in the test_generator, classes contain the raw labels\n",
    "        y_true = np.concatenate([test_generator[i][1] for i in range(len(test_generator))], axis=0)\n",
    "        y_true = np.argmax(y_true, axis=1)\n",
    "\n",
    "        # Compute F1 score\n",
    "        f1 = f1_score(y_true, y_pred, average='macro')  # 'macro' for unweighted mean, 'weighted' for weighted mean\n",
    "        print('F1 Score:', f1)\n",
    "\n",
    "        loss, accuracy = model.evaluate(test_generator, steps=len(test_generator), verbose=0)\n",
    "        print(f'Test loss for the model : {loss:.4f}')\n",
    "        print(f'Test accuracy for the model: {accuracy:.4f}')\n",
    "else:\n",
    "    model = load_model('resnet50.h5')\n",
    "\n",
    "    # Making predictions\n",
    "    y_pred = model.predict(test_generator)\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    # The true labels can be accessed via the classes attribute of the generator\n",
    "    # y_true = test_generator.classes\n",
    "\n",
    "    # Since class_mode was set to 'raw' in the test_generator, classes contain the raw labels\n",
    "    y_true = np.concatenate([test_generator[i][1] for i in range(len(test_generator))], axis=0)\n",
    "    y_true = np.argmax(y_true, axis=1)\n",
    "\n",
    "    # Compute F1 score\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')  # 'macro' for unweighted mean, 'weighted' for weighted mean\n",
    "    print('F1 Score:', f1)\n",
    "\n",
    "    loss, accuracy = model.evaluate(test_generator, steps=len(test_generator), verbose=0)\n",
    "    print(f'Test loss for the model : {loss:.4f}')\n",
    "    print(f'Test accuracy for the model: {accuracy:.4f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attractive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 36000 validated image filenames.\n",
      "Found 9000 validated image filenames.\n",
      "Found 5000 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "attr = pd.read_csv('list_attr_celeba.csv')\n",
    "features = ['image_id', 'Attractive']\n",
    "\n",
    "attr_selected = attr.loc[:, features].iloc[:50000,:]\n",
    "attr_selected = attr_selected.replace(-1,0)\n",
    "\n",
    "train_df, test_df = train_test_split(attr_selected, test_size=0.1)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2)\n",
    "\n",
    "features = ['Attractive']\n",
    "for feature in features:\n",
    "    train_df[feature] = train_df[feature].astype('float32')\n",
    "    val_df[feature] = val_df[feature].astype('float32')\n",
    "    test_df[feature] = test_df[feature].astype('float32')\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "img_height = 128\n",
    "img_width = 128\n",
    "\n",
    "# Create ImageDataGenerators\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, horizontal_flip=True, zoom_range=0.2, shear_range=0.2)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(train_df, directory=\"img_align_celeba/img_align_celeba\", \n",
    "                                                    x_col=\"image_id\", y_col=features,\n",
    "                                                    target_size=(img_height, img_width), \n",
    "                                                    batch_size=batch_size, class_mode='raw')\n",
    "\n",
    "val_generator = train_datagen.flow_from_dataframe(val_df, directory=\"img_align_celeba/img_align_celeba\", \n",
    "                                                    x_col=\"image_id\", y_col=features,\n",
    "                                                    target_size=(img_height, img_width), \n",
    "                                                    batch_size=batch_size, class_mode='raw')\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(test_df, directory=\"img_align_celeba/img_align_celeba\", \n",
    "                                                  x_col=\"image_id\", y_col=features, \n",
    "                                                  target_size=(img_height, img_width), \n",
    "                                                  batch_size=batch_size, class_mode='raw', shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-01 20:22:24.158081: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-01 20:22:24.158350: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-01 20:22:24.160142: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:786] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorDataset/_1\"\n",
      "op: \"TensorDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 1\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\017TensorDataset:0\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT32\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "2023-06-01 20:22:24.187713: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-01 20:22:24.188033: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-01 20:22:24.436875: W tensorflow/core/framework/dataset.cc:807] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2023-06-01 20:22:24.437245: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype variant\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-01 20:22:24.456393: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-01 20:22:24.456639: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-01 20:22:24.638798: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype variant\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-01 20:22:28.397530: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8900\n",
      "2023-06-01 20:22:30.851823: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8900\n",
      "2023-06-01 20:22:33.694403: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8900\n",
      "2023-06-01 20:22:34.596678: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-06-01 20:22:36.124247: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 25s 150ms/step\n",
      "F1 Score: 0.8005226712633323\n",
      "AUC: 0.8917647637254604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-01 20:22:58.465762: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-01 20:22:58.466041: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-01 20:22:58.467222: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:786] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorDataset/_1\"\n",
      "op: \"TensorDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 1\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\020TensorDataset:42\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT32\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "2023-06-01 20:22:58.484245: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-01 20:22:58.484553: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-01 20:22:58.739860: W tensorflow/core/framework/dataset.cc:807] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2023-06-01 20:22:58.740333: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype variant\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-01 20:22:58.766449: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-01 20:22:58.766754: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-01 20:22:58.987240: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype variant\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss for the model : 0.4126\n",
      "Test accuracy for the model: 0.8014\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "if use_multi_gpu:\n",
    "    with strategy.scope():\n",
    "    # Load the pre-trained model from the h5 file\n",
    "        model = load_model('best_model_attractive.h5')\n",
    "\n",
    "        # Making predictions\n",
    "        y_pred_proba = model.predict(test_generator).flatten()\n",
    "        y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "        # Since class_mode was set to 'raw' in the test_generator, classes contain the raw labels\n",
    "        y_true = np.concatenate([test_generator[i][1] for i in range(len(test_generator))], axis=0).flatten()\n",
    "        # y_true = np.argmax(y_true, axis=1)\n",
    "\n",
    "        # Compute F1 score\n",
    "        f1 = f1_score(y_true, y_pred, average='weighted')  # 'macro' for unweighted mean, 'weighted' for weighted mean\n",
    "        print('F1 Score:', f1)\n",
    "\n",
    "        auc = roc_auc_score(y_true, y_pred_proba, multi_class='ovr')  # 'ovr' for One-vs-Rest, 'ovo' for One-vs-One\n",
    "        print('AUC:', auc)\n",
    "\n",
    "        loss, accuracy = model.evaluate(test_generator, steps=len(test_generator), verbose=0)\n",
    "        print(f'Test loss for the model : {loss:.4f}')\n",
    "        print(f'Test accuracy for the model: {accuracy:.4f}')\n",
    "else:\n",
    "    model = load_model('best_model_attractive.h5')\n",
    "\n",
    "    # Making predictions\n",
    "    y_pred_proba = model.predict(test_generator).flatten()\n",
    "    y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "    # Since class_mode was set to 'raw' in the test_generator, classes contain the raw labels\n",
    "    y_true = np.concatenate([test_generator[i][1] for i in range(len(test_generator))], axis=0).flatten()\n",
    "    # y_true = np.argmax(y_true, axis=1)\n",
    "\n",
    "    # Compute F1 score\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')  # 'macro' for unweighted mean, 'weighted' for weighted mean\n",
    "    print('F1 Score:', f1)\n",
    "\n",
    "    auc = roc_auc_score(y_true, y_pred_proba, multi_class='ovr')  # 'ovr' for One-vs-Rest, 'ovo' for One-vs-One\n",
    "    print('AUC:', auc)\n",
    "\n",
    "    loss, accuracy = model.evaluate(test_generator, steps=len(test_generator), verbose=0)\n",
    "    print(f'Test loss for the model : {loss:.4f}')\n",
    "    print(f'Test accuracy for the model: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-01 20:23:31.749114: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-01 20:23:31.749349: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-01 20:23:31.750517: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:786] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorDataset/_1\"\n",
      "op: \"TensorDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 1\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\020TensorDataset:84\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT32\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "2023-06-01 20:23:31.767908: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-01 20:23:31.768200: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-01 20:23:31.955014: W tensorflow/core/framework/dataset.cc:807] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2023-06-01 20:23:31.955361: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype variant\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-01 20:23:31.974829: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-01 20:23:31.975042: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-01 20:23:32.168398: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype variant\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 19s 168ms/step\n",
      "F1 Score: 0.6976696925459894\n",
      "AUC: 0.8445248300347642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-01 20:23:56.092933: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-01 20:23:56.093172: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-01 20:23:56.094353: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:786] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorDataset/_1\"\n",
      "op: \"TensorDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 1\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\021TensorDataset:126\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT32\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "2023-06-01 20:23:56.111501: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-01 20:23:56.111747: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-01 20:23:56.301598: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype variant\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-01 20:23:56.321490: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-01 20:23:56.321743: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-01 20:23:56.503886: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype variant\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss for the model : 0.5964\n",
      "Test accuracy for the model: 0.7074\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "if use_multi_gpu:\n",
    "    with strategy.scope():\n",
    "    # Load the pre-trained model from the h5 file\n",
    "        model = load_model('resnet_attractive.h5')\n",
    "\n",
    "        # Making predictions\n",
    "        y_pred_proba = model.predict(test_generator).flatten()\n",
    "        y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "        # The true labels can be accessed via the classes attribute of the generator\n",
    "        # y_true = test_generator.classes\n",
    "\n",
    "        # Since class_mode was set to 'raw' in the test_generator, classes contain the raw labels\n",
    "        y_true = np.concatenate([test_generator[i][1] for i in range(len(test_generator))], axis=0).flatten()\n",
    "        # y_true = np.argmax(y_true, axis=1)\n",
    "\n",
    "        # Compute F1 score\n",
    "        f1 = f1_score(y_true, y_pred, average='macro')  # 'macro' for unweighted mean, 'weighted' for weighted mean\n",
    "        print('F1 Score:', f1)\n",
    "\n",
    "        auc = roc_auc_score(y_true, y_pred_proba, multi_class='ovr')  # 'ovr' for One-vs-Rest, 'ovo' for One-vs-One\n",
    "        print('AUC:', auc)\n",
    "\n",
    "        loss, accuracy = model.evaluate(test_generator, steps=len(test_generator), verbose=0)\n",
    "        print(f'Test loss for the model : {loss:.4f}')\n",
    "        print(f'Test accuracy for the model: {accuracy:.4f}')\n",
    "else:\n",
    "    model = load_model('resnet_attractive.h5')\n",
    "\n",
    "    # Making predictions\n",
    "    y_pred_proba = model.predict(test_generator).flatten()\n",
    "    y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "    # The true labels can be accessed via the classes attribute of the generator\n",
    "    # y_true = test_generator.classes\n",
    "\n",
    "    # Since class_mode was set to 'raw' in the test_generator, classes contain the raw labels\n",
    "    y_true = np.concatenate([test_generator[i][1] for i in range(len(test_generator))], axis=0).flatten()\n",
    "    # y_true = np.argmax(y_true, axis=1)\n",
    "\n",
    "    # Compute F1 score\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')  # 'macro' for unweighted mean, 'weighted' for weighted mean\n",
    "    print('F1 Score:', f1)\n",
    "\n",
    "    auc = roc_auc_score(y_true, y_pred_proba, multi_class='ovr')  # 'ovr' for One-vs-Rest, 'ovo' for One-vs-One\n",
    "    print('AUC:', auc)\n",
    "\n",
    "    loss, accuracy = model.evaluate(test_generator, steps=len(test_generator), verbose=0)\n",
    "    print(f'Test loss for the model : {loss:.4f}')\n",
    "    print(f'Test accuracy for the model: {accuracy:.4f}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bangs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 36000 validated image filenames.\n",
      "Found 9000 validated image filenames.\n",
      "Found 5000 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "attr = pd.read_csv('list_attr_celeba.csv')\n",
    "features = ['image_id', 'Bangs']\n",
    "\n",
    "attr_selected = attr.loc[:, features].iloc[:50000,:]\n",
    "attr_selected = attr_selected.replace(-1,0)\n",
    "\n",
    "train_df, test_df = train_test_split(attr_selected, test_size=0.1)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2)\n",
    "\n",
    "features = ['Bangs']\n",
    "for feature in features:\n",
    "    train_df[feature] = train_df[feature].astype('float32')\n",
    "    val_df[feature] = val_df[feature].astype('float32')\n",
    "    test_df[feature] = test_df[feature].astype('float32')\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "img_height = 128\n",
    "img_width = 128\n",
    "\n",
    "# Create ImageDataGenerators\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, horizontal_flip=True, zoom_range=0.2, shear_range=0.2)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(train_df, directory=\"img_align_celeba/img_align_celeba\", \n",
    "                                                    x_col=\"image_id\", y_col=features,\n",
    "                                                    target_size=(img_height, img_width), \n",
    "                                                    batch_size=batch_size, class_mode='raw')\n",
    "\n",
    "val_generator = train_datagen.flow_from_dataframe(val_df, directory=\"img_align_celeba/img_align_celeba\", \n",
    "                                                    x_col=\"image_id\", y_col=features,\n",
    "                                                    target_size=(img_height, img_width), \n",
    "                                                    batch_size=batch_size, class_mode='raw')\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(test_df, directory=\"img_align_celeba/img_align_celeba\", \n",
    "                                                  x_col=\"image_id\", y_col=features, \n",
    "                                                  target_size=(img_height, img_width), \n",
    "                                                  batch_size=batch_size, class_mode='raw', shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-01 20:24:34.507009: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-01 20:24:34.507384: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-01 20:24:34.509468: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:786] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorDataset/_1\"\n",
      "op: \"TensorDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 1\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\021TensorDataset:168\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT32\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "2023-06-01 20:24:34.529493: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-01 20:24:34.529907: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-01 20:24:34.806173: W tensorflow/core/framework/dataset.cc:807] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2023-06-01 20:24:34.806714: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype variant\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-01 20:24:34.834346: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-01 20:24:34.834694: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-01 20:24:35.103558: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype variant\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 15s 168ms/step\n",
      "F1 Score: 0.9168627450980393\n",
      "AUC: 0.9867186867722846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-01 20:24:58.297480: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-01 20:24:58.297763: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-01 20:24:58.299026: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:786] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorDataset/_1\"\n",
      "op: \"TensorDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 1\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\021TensorDataset:210\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT32\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "2023-06-01 20:24:58.315622: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-01 20:24:58.315925: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-01 20:24:58.572040: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype variant\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-01 20:24:58.597648: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-01 20:24:58.597953: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-01 20:24:58.848630: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype variant\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss for the model : 0.1053\n",
      "Test accuracy for the model: 0.9576\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "if use_multi_gpu:\n",
    "    with strategy.scope():\n",
    "    # Load the pre-trained model from the h5 file\n",
    "        model = load_model('best_model_bangs.h5')\n",
    "\n",
    "        # Making predictions\n",
    "        y_pred_proba = model.predict(test_generator).flatten()\n",
    "        y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "        # The true labels can be accessed via the classes attribute of the generator\n",
    "        # y_true = test_generator.classes\n",
    "\n",
    "        # Since class_mode was set to 'raw' in the test_generator, classes contain the raw labels\n",
    "        y_true = np.concatenate([test_generator[i][1] for i in range(len(test_generator))], axis=0).flatten()\n",
    "\n",
    "        # Compute F1 score\n",
    "        f1 = f1_score(y_true, y_pred, average='macro')  # 'macro' for unweighted mean, 'weighted' for weighted mean\n",
    "        print('F1 Score:', f1)\n",
    "\n",
    "        auc = roc_auc_score(y_true, y_pred_proba, multi_class='ovr')  # 'ovr' for One-vs-Rest, 'ovo' for One-vs-One\n",
    "        print('AUC:', auc)\n",
    "\n",
    "        loss, accuracy = model.evaluate(test_generator, steps=len(test_generator), verbose=0)\n",
    "        print(f'Test loss for the model : {loss:.4f}')\n",
    "        print(f'Test accuracy for the model: {accuracy:.4f}')\n",
    "else:\n",
    "    model = load_model('best_model_bangs.h5')\n",
    "\n",
    "    # Making predictions\n",
    "    y_pred_proba = model.predict(test_generator).flatten()\n",
    "    y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "    # The true labels can be accessed via the classes attribute of the generator\n",
    "    # y_true = test_generator.classes\n",
    "\n",
    "    # Since class_mode was set to 'raw' in the test_generator, classes contain the raw labels\n",
    "    y_true = np.concatenate([test_generator[i][1] for i in range(len(test_generator))], axis=0).flatten()\n",
    "\n",
    "    # Compute F1 score\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')  # 'macro' for unweighted mean, 'weighted' for weighted mean\n",
    "    print('F1 Score:', f1)\n",
    "\n",
    "    auc = roc_auc_score(y_true, y_pred_proba, multi_class='ovr')  # 'ovr' for One-vs-Rest, 'ovo' for One-vs-One\n",
    "    print('AUC:', auc)\n",
    "\n",
    "    loss, accuracy = model.evaluate(test_generator, steps=len(test_generator), verbose=0)\n",
    "    print(f'Test loss for the model : {loss:.4f}')\n",
    "    print(f'Test accuracy for the model: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-01 20:25:29.005866: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-01 20:25:29.006059: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-01 20:25:29.006913: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:786] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorDataset/_1\"\n",
      "op: \"TensorDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 1\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\021TensorDataset:252\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT32\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "2023-06-01 20:25:29.022451: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-01 20:25:29.022677: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-01 20:25:29.207303: W tensorflow/core/framework/dataset.cc:807] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2023-06-01 20:25:29.207706: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype variant\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-01 20:25:29.227918: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-01 20:25:29.228198: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-01 20:25:29.420250: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype variant\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 21s 186ms/step\n",
      "F1 Score: 0.8604089937617805\n",
      "AUC: 0.9630967741935483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-01 20:25:59.218881: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-01 20:25:59.219282: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-01 20:25:59.221199: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:786] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorDataset/_1\"\n",
      "op: \"TensorDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 1\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\021TensorDataset:294\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT32\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "2023-06-01 20:25:59.243407: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-01 20:25:59.243777: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-01 20:25:59.475991: W tensorflow/core/framework/dataset.cc:807] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2023-06-01 20:25:59.476392: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype variant\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-01 20:25:59.496748: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-01 20:25:59.497009: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-01 20:25:59.679399: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype variant\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss for the model : 0.1738\n",
      "Test accuracy for the model: 0.9292\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "if use_multi_gpu:\n",
    "    with strategy.scope():\n",
    "    # Load the pre-trained model from the h5 file\n",
    "        model = load_model('resnet_bangs.h5')\n",
    "\n",
    "        # Making predictions\n",
    "        y_pred_proba = model.predict(test_generator).flatten()\n",
    "        y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "        # The true labels can be accessed via the classes attribute of the generator\n",
    "        # y_true = test_generator.classes\n",
    "\n",
    "        # Since class_mode was set to 'raw' in the test_generator, classes contain the raw labels\n",
    "        y_true = np.concatenate([test_generator[i][1] for i in range(len(test_generator))], axis=0).flatten()\n",
    "\n",
    "        # Compute F1 score\n",
    "        f1 = f1_score(y_true, y_pred, average='macro')  # 'macro' for unweighted mean, 'weighted' for weighted mean\n",
    "        print('F1 Score:', f1)\n",
    "\n",
    "        auc = roc_auc_score(y_true, y_pred_proba, multi_class='ovr')  # 'ovr' for One-vs-Rest, 'ovo' for One-vs-One\n",
    "        print('AUC:', auc)\n",
    "\n",
    "        loss, accuracy = model.evaluate(test_generator, steps=len(test_generator), verbose=0)\n",
    "        print(f'Test loss for the model : {loss:.4f}')\n",
    "        print(f'Test accuracy for the model: {accuracy:.4f}')\n",
    "else:\n",
    "    model = load_model('resnet_bangs.h5')\n",
    "\n",
    "    # Making predictions\n",
    "    y_pred_proba = model.predict(test_generator).flatten()\n",
    "    y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "    # The true labels can be accessed via the classes attribute of the generator\n",
    "    # y_true = test_generator.classes\n",
    "\n",
    "    # Since class_mode was set to 'raw' in the test_generator, classes contain the raw labels\n",
    "    y_true = np.concatenate([test_generator[i][1] for i in range(len(test_generator))], axis=0).flatten()\n",
    "\n",
    "    # Compute F1 score\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')  # 'macro' for unweighted mean, 'weighted' for weighted mean\n",
    "    print('F1 Score:', f1)\n",
    "\n",
    "    auc = roc_auc_score(y_true, y_pred_proba, multi_class='ovr')  # 'ovr' for One-vs-Rest, 'ovo' for One-vs-One\n",
    "    print('AUC:', auc)\n",
    "\n",
    "    loss, accuracy = model.evaluate(test_generator, steps=len(test_generator), verbose=0)\n",
    "    print(f'Test loss for the model : {loss:.4f}')\n",
    "    print(f'Test accuracy for the model: {accuracy:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
