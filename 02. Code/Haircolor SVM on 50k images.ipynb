{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6675762-b7bb-415b-b629-92119bbfe09a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>5_o_Clock_Shadow</th>\n",
       "      <th>Arched_Eyebrows</th>\n",
       "      <th>Attractive</th>\n",
       "      <th>Bags_Under_Eyes</th>\n",
       "      <th>Bald</th>\n",
       "      <th>Bangs</th>\n",
       "      <th>Big_Lips</th>\n",
       "      <th>Big_Nose</th>\n",
       "      <th>Black_Hair</th>\n",
       "      <th>...</th>\n",
       "      <th>Sideburns</th>\n",
       "      <th>Smiling</th>\n",
       "      <th>Straight_Hair</th>\n",
       "      <th>Wavy_Hair</th>\n",
       "      <th>Wearing_Earrings</th>\n",
       "      <th>Wearing_Hat</th>\n",
       "      <th>Wearing_Lipstick</th>\n",
       "      <th>Wearing_Necklace</th>\n",
       "      <th>Wearing_Necktie</th>\n",
       "      <th>Young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000001.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000002.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000003.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000004.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000005.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202594</th>\n",
       "      <td>202595.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202595</th>\n",
       "      <td>202596.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202596</th>\n",
       "      <td>202597.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202597</th>\n",
       "      <td>202598.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202598</th>\n",
       "      <td>202599.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202599 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          image_id  5_o_Clock_Shadow  Arched_Eyebrows  Attractive   \n",
       "0       000001.jpg                -1                1           1  \\\n",
       "1       000002.jpg                -1               -1          -1   \n",
       "2       000003.jpg                -1               -1          -1   \n",
       "3       000004.jpg                -1               -1           1   \n",
       "4       000005.jpg                -1                1           1   \n",
       "...            ...               ...              ...         ...   \n",
       "202594  202595.jpg                -1               -1           1   \n",
       "202595  202596.jpg                -1               -1          -1   \n",
       "202596  202597.jpg                -1               -1          -1   \n",
       "202597  202598.jpg                -1                1           1   \n",
       "202598  202599.jpg                -1                1           1   \n",
       "\n",
       "        Bags_Under_Eyes  Bald  Bangs  Big_Lips  Big_Nose  Black_Hair  ...   \n",
       "0                    -1    -1     -1        -1        -1          -1  ...  \\\n",
       "1                     1    -1     -1        -1         1          -1  ...   \n",
       "2                    -1    -1     -1         1        -1          -1  ...   \n",
       "3                    -1    -1     -1        -1        -1          -1  ...   \n",
       "4                    -1    -1     -1         1        -1          -1  ...   \n",
       "...                 ...   ...    ...       ...       ...         ...  ...   \n",
       "202594               -1    -1     -1         1        -1          -1  ...   \n",
       "202595               -1    -1      1         1        -1          -1  ...   \n",
       "202596               -1    -1     -1        -1        -1           1  ...   \n",
       "202597               -1    -1     -1         1        -1           1  ...   \n",
       "202598               -1    -1     -1        -1        -1          -1  ...   \n",
       "\n",
       "        Sideburns  Smiling  Straight_Hair  Wavy_Hair  Wearing_Earrings   \n",
       "0              -1        1              1         -1                 1  \\\n",
       "1              -1        1             -1         -1                -1   \n",
       "2              -1       -1             -1          1                -1   \n",
       "3              -1       -1              1         -1                 1   \n",
       "4              -1       -1             -1         -1                -1   \n",
       "...           ...      ...            ...        ...               ...   \n",
       "202594         -1       -1             -1         -1                -1   \n",
       "202595         -1        1              1         -1                -1   \n",
       "202596         -1        1             -1         -1                -1   \n",
       "202597         -1        1             -1          1                 1   \n",
       "202598         -1       -1             -1          1                -1   \n",
       "\n",
       "        Wearing_Hat  Wearing_Lipstick  Wearing_Necklace  Wearing_Necktie   \n",
       "0                -1                 1                -1               -1  \\\n",
       "1                -1                -1                -1               -1   \n",
       "2                -1                -1                -1               -1   \n",
       "3                -1                 1                 1               -1   \n",
       "4                -1                 1                -1               -1   \n",
       "...             ...               ...               ...              ...   \n",
       "202594           -1                 1                -1               -1   \n",
       "202595           -1                -1                -1               -1   \n",
       "202596           -1                -1                -1               -1   \n",
       "202597           -1                 1                -1               -1   \n",
       "202598           -1                 1                -1               -1   \n",
       "\n",
       "        Young  \n",
       "0           1  \n",
       "1           1  \n",
       "2           1  \n",
       "3           1  \n",
       "4           1  \n",
       "...       ...  \n",
       "202594      1  \n",
       "202595      1  \n",
       "202596      1  \n",
       "202597      1  \n",
       "202598      1  \n",
       "\n",
       "[202599 rows x 41 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"TabularDatasets/list_attr_celeba.csv\", header='infer')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95168e77-6045-4dcf-b01c-2a260aa0a161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['image_id', '5_o_Clock_Shadow', 'Arched_Eyebrows', 'Attractive',\n",
       "       'Bags_Under_Eyes', 'Bald', 'Bangs', 'Big_Lips', 'Big_Nose',\n",
       "       'Black_Hair', 'Blond_Hair', 'Blurry', 'Brown_Hair', 'Bushy_Eyebrows',\n",
       "       'Chubby', 'Double_Chin', 'Eyeglasses', 'Goatee', 'Gray_Hair',\n",
       "       'Heavy_Makeup', 'High_Cheekbones', 'Male', 'Mouth_Slightly_Open',\n",
       "       'Mustache', 'Narrow_Eyes', 'No_Beard', 'Oval_Face', 'Pale_Skin',\n",
       "       'Pointy_Nose', 'Receding_Hairline', 'Rosy_Cheeks', 'Sideburns',\n",
       "       'Smiling', 'Straight_Hair', 'Wavy_Hair', 'Wearing_Earrings',\n",
       "       'Wearing_Hat', 'Wearing_Lipstick', 'Wearing_Necklace',\n",
       "       'Wearing_Necktie', 'Young'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e21fb7ea-064e-48cc-abd4-b62a405498ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>Black_Hair</th>\n",
       "      <th>Blond_Hair</th>\n",
       "      <th>Brown_Hair</th>\n",
       "      <th>Gray_Hair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000001.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000002.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000003.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000004.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000005.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_id  Black_Hair  Blond_Hair  Brown_Hair  Gray_Hair\n",
       "0  000001.jpg          -1          -1           1         -1\n",
       "1  000002.jpg          -1          -1           1         -1\n",
       "2  000003.jpg          -1          -1          -1         -1\n",
       "3  000004.jpg          -1          -1          -1         -1\n",
       "4  000005.jpg          -1          -1          -1         -1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hair_cols = ['image_id','Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Gray_Hair']\n",
    "df_hair = df[hair_cols]\n",
    "df_hair.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a001a9-1cfa-42af-a242-0d41f97ec3f1",
   "metadata": {},
   "source": [
    "Test with 100 samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42af2cf1-fe69-4d2b-9046-8d5e81281a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.55\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from multiprocessing import Pool\n",
    "import os\n",
    "\n",
    "\n",
    "# Function to load and preprocess a single image\n",
    "def process_image(image_name):\n",
    "    image_path = os.path.join(image_folder_path, image_name)\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Unable to open {image_path}. Skipping.\")\n",
    "        return None\n",
    "    image = cv2.resize(image, (32, 32))  # use a lower resolution\n",
    "    return image.flatten()\n",
    "\n",
    "# Load dataframe\n",
    "#df = pd.read_csv('your_dataframe.csv')\n",
    "\n",
    "# Randomly sample 10,000 images from the dataframe\n",
    "df_sample = df_hair.sample(n=100, random_state=1)\n",
    "\n",
    "# Load and preprocess images\n",
    "image_folder_path = 'img_align_celeba/'\n",
    "\n",
    "# Use multiprocessing to load and preprocess images\n",
    "with Pool(os.cpu_count()) as p:\n",
    "    images = p.map(process_image, df_sample['image_id'])\n",
    "\n",
    "# Filter out any images that couldn't be opened\n",
    "images = [image for image in images if image is not None]\n",
    "\n",
    "# Convert list of images to numpy array\n",
    "images = np.array(images)\n",
    "\n",
    "# Prepare labels\n",
    "labels = df_sample[['Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Gray_Hair']].values\n",
    "labels = np.argmax(labels, axis=1)  # convert from one-hot encoding to single label\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Train SVM\n",
    "clf = svm.SVC(gamma='scale')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Check accuracy on test set\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print('Accuracy: ', accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ee402f-77d7-40f8-bbbc-1b350a40f480",
   "metadata": {},
   "source": [
    "Test with 1000 samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39ff3971-1ee1-4bc4-906f-0c461221cc69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.635\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from multiprocessing import Pool\n",
    "import os\n",
    "\n",
    "\n",
    "# Function to load and preprocess a single image\n",
    "def process_image(image_name):\n",
    "    image_path = os.path.join(image_folder_path, image_name)\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Unable to open {image_path}. Skipping.\")\n",
    "        return None\n",
    "    image = cv2.resize(image, (32, 32))  # use a lower resolution\n",
    "    return image.flatten()\n",
    "\n",
    "# Load dataframe\n",
    "#df = pd.read_csv('your_dataframe.csv')\n",
    "\n",
    "# Randomly sample 10,000 images from the dataframe\n",
    "df_sample = df_hair.sample(n=1000, random_state=1)\n",
    "\n",
    "# Load and preprocess images\n",
    "image_folder_path = 'img_align_celeba/'\n",
    "\n",
    "# Use multiprocessing to load and preprocess images\n",
    "with Pool(os.cpu_count()) as p:\n",
    "    images = p.map(process_image, df_sample['image_id'])\n",
    "\n",
    "# Filter out any images that couldn't be opened\n",
    "images = [image for image in images if image is not None]\n",
    "\n",
    "# Convert list of images to numpy array\n",
    "images = np.array(images)\n",
    "\n",
    "# Prepare labels\n",
    "labels = df_sample[['Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Gray_Hair']].values\n",
    "labels = np.argmax(labels, axis=1)  # convert from one-hot encoding to single label\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Train SVM\n",
    "clf = svm.SVC(gamma='scale')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Check accuracy on test set\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print('Accuracy: ', accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a3f121-711e-4857-a4ff-04599d8e7786",
   "metadata": {},
   "source": [
    "Same test but with higher resolution images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2b5f4d2-e94e-444d-903e-61dcb427a068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.64\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from multiprocessing import Pool\n",
    "import os\n",
    "\n",
    "\n",
    "# Function to load and preprocess a single image\n",
    "def process_image(image_name):\n",
    "    image_path = os.path.join(image_folder_path, image_name)\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Unable to open {image_path}. Skipping.\")\n",
    "        return None\n",
    "    image = cv2.resize(image, (64, 64))  # use a lower resolution\n",
    "    return image.flatten()\n",
    "\n",
    "# Load dataframe\n",
    "#df = pd.read_csv('your_dataframe.csv')\n",
    "\n",
    "# Randomly sample 10,000 images from the dataframe\n",
    "df_sample = df_hair.sample(n=1000, random_state=1)\n",
    "\n",
    "# Load and preprocess images\n",
    "image_folder_path = 'img_align_celeba/'\n",
    "\n",
    "# Use multiprocessing to load and preprocess images\n",
    "with Pool(os.cpu_count()) as p:\n",
    "    images = p.map(process_image, df_sample['image_id'])\n",
    "\n",
    "# Filter out any images that couldn't be opened\n",
    "images = [image for image in images if image is not None]\n",
    "\n",
    "# Convert list of images to numpy array\n",
    "images = np.array(images)\n",
    "\n",
    "# Prepare labels\n",
    "labels = df_sample[['Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Gray_Hair']].values\n",
    "labels = np.argmax(labels, axis=1)  # convert from one-hot encoding to single label\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Train SVM\n",
    "clf = svm.SVC(gamma='scale')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Check accuracy on test set\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print('Accuracy: ', accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12943ca9-86ab-4e87-972d-eab2688e0c28",
   "metadata": {},
   "source": [
    "Same test but with lower resolution images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78541abc-6431-4b4d-afed-d6938458dfbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.62\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from multiprocessing import Pool\n",
    "import os\n",
    "\n",
    "\n",
    "# Function to load and preprocess a single image\n",
    "def process_image(image_name):\n",
    "    image_path = os.path.join(image_folder_path, image_name)\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Unable to open {image_path}. Skipping.\")\n",
    "        return None\n",
    "    image = cv2.resize(image, (16, 16))  # use a lower resolution\n",
    "    return image.flatten()\n",
    "\n",
    "# Load dataframe\n",
    "#df = pd.read_csv('your_dataframe.csv')\n",
    "\n",
    "# Randomly sample 10,000 images from the dataframe\n",
    "df_sample = df_hair.sample(n=1000, random_state=1)\n",
    "\n",
    "# Load and preprocess images\n",
    "image_folder_path = 'img_align_celeba/'\n",
    "\n",
    "# Use multiprocessing to load and preprocess images\n",
    "with Pool(os.cpu_count()) as p:\n",
    "    images = p.map(process_image, df_sample['image_id'])\n",
    "\n",
    "# Filter out any images that couldn't be opened\n",
    "images = [image for image in images if image is not None]\n",
    "\n",
    "# Convert list of images to numpy array\n",
    "images = np.array(images)\n",
    "\n",
    "# Prepare labels\n",
    "labels = df_sample[['Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Gray_Hair']].values\n",
    "labels = np.argmax(labels, axis=1)  # convert from one-hot encoding to single label\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Train SVM\n",
    "clf = svm.SVC(gamma='scale')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Check accuracy on test set\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print('Accuracy: ', accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0166185-43d4-464b-93ba-c0e43f62d718",
   "metadata": {},
   "source": [
    "Test with 10,000 samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a92e2edf-2586-425b-9842-767174bf3479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.73\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from multiprocessing import Pool\n",
    "import os\n",
    "\n",
    "\n",
    "# Function to load and preprocess a single image\n",
    "def process_image(image_name):\n",
    "    image_path = os.path.join(image_folder_path, image_name)\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Unable to open {image_path}. Skipping.\")\n",
    "        return None\n",
    "    image = cv2.resize(image, (32, 32))  # use a lower resolution\n",
    "    return image.flatten()\n",
    "\n",
    "# Load dataframe\n",
    "#df = pd.read_csv('your_dataframe.csv')\n",
    "\n",
    "# Randomly sample 10,000 images from the dataframe\n",
    "df_sample = df_hair.sample(n=10000, random_state=1)\n",
    "\n",
    "# Load and preprocess images\n",
    "image_folder_path = 'img_align_celeba/'\n",
    "\n",
    "# Use multiprocessing to load and preprocess images\n",
    "with Pool(os.cpu_count()) as p:\n",
    "    images = p.map(process_image, df_sample['image_id'])\n",
    "\n",
    "# Filter out any images that couldn't be opened\n",
    "images = [image for image in images if image is not None]\n",
    "\n",
    "# Convert list of images to numpy array\n",
    "images = np.array(images)\n",
    "\n",
    "# Prepare labels\n",
    "labels = df_sample[['Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Gray_Hair']].values\n",
    "labels = np.argmax(labels, axis=1)  # convert from one-hot encoding to single label\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Train SVM\n",
    "clf = svm.SVC(gamma='scale')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Check accuracy on test set\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print('Accuracy: ', accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070e439f-b361-4e8b-a7fd-38ee1a705d8a",
   "metadata": {},
   "source": [
    "Same test with lower resolution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b4434f9-215b-45f8-a07c-0515977ab7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7275\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from multiprocessing import Pool\n",
    "import os\n",
    "\n",
    "\n",
    "# Function to load and preprocess a single image\n",
    "def process_image(image_name):\n",
    "    image_path = os.path.join(image_folder_path, image_name)\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Unable to open {image_path}. Skipping.\")\n",
    "        return None\n",
    "    image = cv2.resize(image, (16, 16))  # use a lower resolution\n",
    "    return image.flatten()\n",
    "\n",
    "# Load dataframe\n",
    "#df = pd.read_csv('your_dataframe.csv')\n",
    "\n",
    "# Randomly sample 10,000 images from the dataframe\n",
    "df_sample = df_hair.sample(n=10000, random_state=1)\n",
    "\n",
    "# Load and preprocess images\n",
    "image_folder_path = 'img_align_celeba/'\n",
    "\n",
    "# Use multiprocessing to load and preprocess images\n",
    "with Pool(os.cpu_count()) as p:\n",
    "    images = p.map(process_image, df_sample['image_id'])\n",
    "\n",
    "# Filter out any images that couldn't be opened\n",
    "images = [image for image in images if image is not None]\n",
    "\n",
    "# Convert list of images to numpy array\n",
    "images = np.array(images)\n",
    "\n",
    "# Prepare labels\n",
    "labels = df_sample[['Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Gray_Hair']].values\n",
    "labels = np.argmax(labels, axis=1)  # convert from one-hot encoding to single label\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Train SVM\n",
    "clf = svm.SVC(gamma='scale')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Check accuracy on test set\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print('Accuracy: ', accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28710ae2-3813-461f-a883-3f8c6f94bfef",
   "metadata": {},
   "source": [
    "Test with 25,000 samples: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07055e6e-4f4f-4b71-babc-4d2453a0e4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7408\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from multiprocessing import Pool\n",
    "import os\n",
    "\n",
    "\n",
    "# Function to load and preprocess a single image\n",
    "def process_image(image_name):\n",
    "    image_path = os.path.join(image_folder_path, image_name)\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Unable to open {image_path}. Skipping.\")\n",
    "        return None\n",
    "    image = cv2.resize(image, (16, 16))  # use a lower resolution\n",
    "    return image.flatten()\n",
    "\n",
    "# Load dataframe\n",
    "#df = pd.read_csv('your_dataframe.csv')\n",
    "\n",
    "# Randomly sample 10,000 images from the dataframe\n",
    "df_sample = df_hair.sample(n=25000, random_state=1)\n",
    "\n",
    "# Load and preprocess images\n",
    "image_folder_path = 'img_align_celeba/'\n",
    "\n",
    "# Use multiprocessing to load and preprocess images\n",
    "with Pool(os.cpu_count()) as p:\n",
    "    images = p.map(process_image, df_sample['image_id'])\n",
    "\n",
    "# Filter out any images that couldn't be opened\n",
    "images = [image for image in images if image is not None]\n",
    "\n",
    "# Convert list of images to numpy array\n",
    "images = np.array(images)\n",
    "\n",
    "# Prepare labels\n",
    "labels = df_sample[['Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Gray_Hair']].values\n",
    "labels = np.argmax(labels, axis=1)  # convert from one-hot encoding to single label\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Train SVM\n",
    "clf = svm.SVC(gamma='scale')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Check accuracy on test set\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print('Accuracy: ', accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a827e680-6c1d-429d-9d93-967523c5bdbf",
   "metadata": {},
   "source": [
    "Test with 50,000 samples: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d47da7d9-6111-4fa7-984b-585b395a04c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.744\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from multiprocessing import Pool\n",
    "import os\n",
    "\n",
    "\n",
    "# Function to load and preprocess a single image\n",
    "def process_image(image_name):\n",
    "    image_path = os.path.join(image_folder_path, image_name)\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Unable to open {image_path}. Skipping.\")\n",
    "        return None\n",
    "    image = cv2.resize(image, (16, 16))  # use a lower resolution\n",
    "    return image.flatten()\n",
    "\n",
    "# Load dataframe\n",
    "#df = pd.read_csv('your_dataframe.csv')\n",
    "\n",
    "# Randomly sample 10,000 images from the dataframe\n",
    "df_sample = df_hair.sample(n=50000, random_state=1)\n",
    "\n",
    "# Load and preprocess images\n",
    "image_folder_path = 'img_align_celeba/'\n",
    "\n",
    "# Use multiprocessing to load and preprocess images\n",
    "with Pool(os.cpu_count()) as p:\n",
    "    images = p.map(process_image, df_sample['image_id'])\n",
    "\n",
    "# Filter out any images that couldn't be opened\n",
    "images = [image for image in images if image is not None]\n",
    "\n",
    "# Convert list of images to numpy array\n",
    "images = np.array(images)\n",
    "\n",
    "# Prepare labels\n",
    "labels = df_sample[['Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Gray_Hair']].values\n",
    "labels = np.argmax(labels, axis=1)  # convert from one-hot encoding to single label\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Train SVM\n",
    "clf = svm.SVC(gamma='scale')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Check accuracy on test set\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print('Accuracy: ', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed71b8a4-dc92-4690-a69c-13d352bf4c1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>Attractive</th>\n",
       "      <th>Bangs</th>\n",
       "      <th>Black_Hair</th>\n",
       "      <th>Blond_Hair</th>\n",
       "      <th>Brown_Hair</th>\n",
       "      <th>Gray_Hair</th>\n",
       "      <th>Male</th>\n",
       "      <th>Oval_Face</th>\n",
       "      <th>Receding_Hairline</th>\n",
       "      <th>Smiling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000001.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000002.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000003.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000004.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000005.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_id  Attractive  Bangs  Black_Hair  Blond_Hair  Brown_Hair   \n",
       "0  000001.jpg           1     -1          -1          -1           1  \\\n",
       "1  000002.jpg          -1     -1          -1          -1           1   \n",
       "2  000003.jpg          -1     -1          -1          -1          -1   \n",
       "3  000004.jpg           1     -1          -1          -1          -1   \n",
       "4  000005.jpg           1     -1          -1          -1          -1   \n",
       "\n",
       "   Gray_Hair  Male  Oval_Face  Receding_Hairline  Smiling  \n",
       "0         -1    -1         -1                 -1        1  \n",
       "1         -1    -1         -1                 -1        1  \n",
       "2         -1     1         -1                 -1       -1  \n",
       "3         -1    -1         -1                 -1       -1  \n",
       "4         -1    -1         -1                 -1       -1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hair_cols = ['image_id','Attractive', 'Bangs', 'Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Gray_Hair', 'Male', 'Oval_Face', 'Receding_Hairline', 'Smiling']\n",
    "df_hair = df[hair_cols]\n",
    "df_hair.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c83ea892-1802-4b6a-9257-26d9fc372e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.62075\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from multiprocessing import Pool\n",
    "import os\n",
    "\n",
    "\n",
    "# Function to load and preprocess a single image\n",
    "def process_image(image_name):\n",
    "    image_path = os.path.join(image_folder_path, image_name)\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Unable to open {image_path}. Skipping.\")\n",
    "        return None\n",
    "    image = cv2.resize(image, (16, 16))  # use a lower resolution\n",
    "    return image.flatten()\n",
    "\n",
    "# Load dataframe\n",
    "#df = pd.read_csv('your_dataframe.csv')\n",
    "\n",
    "# Randomly sample 10,000 images from the dataframe\n",
    "df_sample = df_hair.sample(n=20000, random_state=1)\n",
    "\n",
    "# Load and preprocess images\n",
    "image_folder_path = 'img_align_celeba/'\n",
    "\n",
    "# Use multiprocessing to load and preprocess images\n",
    "with Pool(os.cpu_count()) as p:\n",
    "    images = p.map(process_image, df_sample['image_id'])\n",
    "\n",
    "# Filter out any images that couldn't be opened\n",
    "images = [image for image in images if image is not None]\n",
    "\n",
    "# Convert list of images to numpy array\n",
    "images = np.array(images)\n",
    "\n",
    "# Prepare labels\n",
    "labels = df_sample[['Attractive', 'Bangs', 'Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Gray_Hair', 'Male', 'Oval_Face', 'Receding_Hairline', 'Smiling']].values\n",
    "labels = np.argmax(labels, axis=1)  # convert from one-hot encoding to single label\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Train SVM\n",
    "clf = svm.SVC(gamma='scale')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Check accuracy on test set\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print('Accuracy: ', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5dde5084-614b-4f76-9e84-14bee73d0468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5008475587853919\n",
      "Recall: 0.62075\n",
      "F1-score: 0.5345078615008201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Predict labels for test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Compute precision, recall, and F1-score\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print('F1-score:', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c17d265d-a4e3-42bf-b9d9-50881ea719dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[2120    2   25    0    0    8   82    0    0    0]\n",
      " [ 203    0    2    0    0    2   16    0    0    0]\n",
      " [ 265    0   62    0    0    0   67    0    0    0]\n",
      " [ 115    0    0    0    0    6   14    0    0    0]\n",
      " [ 169    0    5    0    0    0   22    0    0    0]\n",
      " [  40    0    0    0    0   49   59    0    0    0]\n",
      " [ 254    0   26    0    0   16  252    0    0    0]\n",
      " [  38    0    0    0    0    1   12    0    0    0]\n",
      " [  13    0    1    0    0    0    1    0    0    0]\n",
      " [  48    0    0    0    0    0    5    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix:')\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b4d8190-d7df-499d-b3e8-818e0632db0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.95      0.77      2237\n",
      "           1       0.00      0.00      0.00       223\n",
      "           2       0.51      0.16      0.24       394\n",
      "           3       0.00      0.00      0.00       135\n",
      "           4       0.00      0.00      0.00       196\n",
      "           5       0.60      0.33      0.43       148\n",
      "           6       0.48      0.46      0.47       548\n",
      "           7       0.00      0.00      0.00        51\n",
      "           8       0.00      0.00      0.00        15\n",
      "           9       0.00      0.00      0.00        53\n",
      "\n",
      "    accuracy                           0.62      4000\n",
      "   macro avg       0.22      0.19      0.19      4000\n",
      "weighted avg       0.50      0.62      0.53      4000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print('Classification Report:')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c794178b-105b-4072-b6b6-1fd6d3509e1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef9f6c9-b2b7-466f-8241-d67412403629",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788687a1-4d79-459a-b69c-1e6ecacff68e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d32661-bb65-47f2-94c4-301547fa0564",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e575758-fe28-41ed-9cf7-054837e3996a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4013ddf5-cdaf-46ed-aadf-9f6824642189",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from multiprocessing import Pool\n",
    "import os\n",
    "\n",
    "\n",
    "# Function to load and preprocess a single image\n",
    "def process_image(image_name):\n",
    "    image_path = os.path.join(image_folder_path, image_name)\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Unable to open {image_path}. Skipping.\")\n",
    "        return None\n",
    "    image = cv2.resize(image, (16, 16))  # use a lower resolution\n",
    "    return image.flatten()\n",
    "\n",
    "# Load dataframe\n",
    "#df = pd.read_csv('your_dataframe.csv')\n",
    "\n",
    "# Randomly sample 10,000 images from the dataframe\n",
    "df_sample = df_hair.sample(n=50000, random_state=1)\n",
    "\n",
    "# Load and preprocess images\n",
    "image_folder_path = 'img_align_celeba/'\n",
    "\n",
    "# Use multiprocessing to load and preprocess images\n",
    "with Pool(os.cpu_count()) as p:\n",
    "    images = p.map(process_image, df_sample['image_id'])\n",
    "\n",
    "# Filter out any images that couldn't be opened\n",
    "images = [image for image in images if image is not None]\n",
    "\n",
    "# Convert list of images to numpy array\n",
    "images = np.array(images)\n",
    "\n",
    "# Prepare labels\n",
    "labels = df_sample[['Attractive', 'Bangs', 'Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Gray_Hair', 'Male', 'Oval_Face', 'Receding_Hairline', 'Smiling']].values\n",
    "labels = np.argmax(labels, axis=1)  # convert from one-hot encoding to single label\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Train SVM\n",
    "clf = svm.SVC(gamma='scale')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Check accuracy on test set\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print('Accuracy: ', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff3fec0-475c-4fe1-9416-08e9fb7eb491",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py39) copy",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
